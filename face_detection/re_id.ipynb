{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchreid\n",
    "from scipy.spatial.distance import cosine\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import time\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "#time\n",
    "prev_time = 0\n",
    "\n",
    "# Initializing the models\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "extractor = torchreid.utils.FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# Initializing the DeepSORT tracker\n",
    "tracker = DeepSort(max_age=30, n_init=3)\n",
    "\n",
    "# Gallery to store unique person embeddings\n",
    "gallery = {}\n",
    "next_person_id = 0\n",
    "person_id_map = {}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "min_conf = 0.5\n",
    "while True:\n",
    "    detections = []\n",
    "    check, frame = cap.read()\n",
    "\n",
    "    #getting the fps\n",
    "    cur_time = time.time()\n",
    "    fps = 1/(cur_time - prev_time)\n",
    "    fps = round(fps*100)/100\n",
    "    prev_time = cur_time\n",
    "\n",
    "    if not check:\n",
    "        break\n",
    "    \n",
    "    # YOLO detection\n",
    "    result = yolo_model(frame, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        if box.cls[0] != 0 or box.conf[0] < min_conf:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "    # DeepSORT tracking\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    \n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        \n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "        \n",
    "        # Check if the track ID is in our person_id map\n",
    "        if track_id not in person_id_map:\n",
    "            # New track ID, perform ReID check\n",
    "            cropped = frame[t:b, l:r]\n",
    "            if cropped.size == 0:\n",
    "                continue\n",
    "            \n",
    "            resized = cv2.resize(cropped, (128, 256))\n",
    "            feature = extractor([resized])[0].cpu()\n",
    "\n",
    "            best_match_id = None\n",
    "            best_similarity_score = 0.0\n",
    "\n",
    "            # Compare with gallery\n",
    "            if gallery:\n",
    "                gallery_embeddings = np.array([data['embedding'].numpy() for data in gallery.values()])\n",
    "                similarity_scores = cosine_similarity(\n",
    "                    feature.unsqueeze(0).numpy(),\n",
    "                    gallery_embeddings\n",
    "                )[0]\n",
    "                \n",
    "                max_score_idx = np.argmax(similarity_scores)\n",
    "                best_similarity_score = similarity_scores[max_score_idx]\n",
    "                \n",
    "                # Minimum similarity threshold\n",
    "                if best_similarity_score > 0.6:\n",
    "                    best_match_id = list(gallery.keys())[max_score_idx]\n",
    "\n",
    "            if best_match_id is not None:\n",
    "                # Match found, link the new track_id to the existing person_id\n",
    "                person_id_map[track_id] = best_match_id\n",
    "                print(f\"Track {track_id} matched with known person ID {best_match_id} (score={best_similarity_score:.2f})\")\n",
    "            else:\n",
    "                # No match found, create a new person ID\n",
    "                current_person_id = next_person_id\n",
    "                next_person_id += 1\n",
    "                \n",
    "                gallery[current_person_id] = {'embedding': feature,'face':resized}\n",
    "                person_id_map[track_id] = current_person_id\n",
    "                print(f\"Track {track_id} assigned new person ID {current_person_id}\")\n",
    "\n",
    "        # Get the person_id from the map\n",
    "        person_id = person_id_map[track_id]\n",
    "        \n",
    "        # Draw\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Person {person_id}\", (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.putText(frame,str(fps),(20,50),cv2.FONT_HERSHEY_PLAIN,1.5 ,(0,100,250),2)\n",
    "    cv2.imshow(\"ReID + Tracking\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(gallery)\n",
    "\n",
    "# Set up grid (auto-square layout)\n",
    "cols = min(n, 5)\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "plt.figure(figsize=(3 * cols, 4 * rows))\n",
    "\n",
    "for i, (person_id, data) in enumerate(gallery.items()):\n",
    "    face = data['face']  # Already a NumPy array\n",
    "    \n",
    "    # Plotting each face\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))  # Convert BGR â†’ RGB\n",
    "    plt.title(f\"Person {person_id}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0c5b8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
