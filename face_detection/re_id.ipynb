{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchreid\n",
    "from scipy.spatial.distance import cosine\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import time\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "#time\n",
    "prev_time = 0\n",
    "\n",
    "# Initializing the models\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "extractor = torchreid.utils.FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# Initializing the DeepSORT tracker\n",
    "tracker = DeepSort(max_age=30, n_init=3)\n",
    "\n",
    "# Gallery to store unique person embeddings\n",
    "gallery = {}\n",
    "next_person_id = 0\n",
    "person_id_map = {}\n",
    "\n",
    "#for preset images \n",
    "preset_faces = {\n",
    "    \"Nishan\": \"C:/Users/nisha/OneDrive - Indian Institute of Technology Guwahati/Documents/projects/CCTV/data/nishan.png\",\n",
    "    \n",
    "}\n",
    "\n",
    "for name, path in preset_faces.items():\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image: {path}\")\n",
    "        continue\n",
    "\n",
    "    resized = cv2.resize(img, (128, 256))\n",
    "    feature = extractor([resized])[0].cpu()\n",
    "\n",
    "    gallery[name] = {\n",
    "        'embedding': feature,\n",
    "        'face': resized,\n",
    "        'is_good_enough': True  # Prevent overwriting\n",
    "    }\n",
    "\n",
    "    print(f\"Added {name} to gallery\")\n",
    "\n",
    "\n",
    "#defining a function whether the current image is better than the previously stored images\n",
    "def is_better_image(new_img, old_img):\n",
    "    def sharpness(img):\n",
    "        return cv2.Laplacian(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()\n",
    "\n",
    "    def area(img):\n",
    "        return img.shape[0] * img.shape[1]\n",
    "\n",
    "    return sharpness(new_img) + area(new_img) > sharpness(old_img) + area(old_img)\n",
    "\n",
    "#defining function if the already stored image is good enough to be kept or needs to be replaced\n",
    "\n",
    "def is_good_enough(image, sharp_thresh=100.0, brightness_thresh=(60, 200)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Sharpness using variance of Laplacian\n",
    "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "    # Brightness\n",
    "    mean_brightness = np.mean(gray)\n",
    "\n",
    "    return (\n",
    "        sharpness > sharp_thresh and\n",
    "        brightness_thresh[0] < mean_brightness < brightness_thresh[1]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "min_conf = 0.5\n",
    "while True:\n",
    "    detections = []\n",
    "    check, frame = cap.read()\n",
    "\n",
    "    #getting the fps\n",
    "    cur_time = time.time()\n",
    "    fps = 1/(cur_time - prev_time)\n",
    "    fps = round(fps*100)/100\n",
    "    prev_time = cur_time\n",
    "\n",
    "    if not check:\n",
    "        break\n",
    "    \n",
    "    # YOLO detection\n",
    "    result = yolo_model(frame, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        if box.cls[0] != 0 or box.conf[0] < min_conf:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "    # DeepSORT tracking\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    \n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        \n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "        \n",
    "        # Check if the track ID is in our person_id map\n",
    "        if track_id not in person_id_map:\n",
    "            # New track ID, perform ReID check\n",
    "            cropped = frame[t:b, l:r]\n",
    "            if cropped.size == 0:\n",
    "                continue\n",
    "            \n",
    "            resized = cv2.resize(cropped, (128, 256))\n",
    "            feature = extractor([resized])[0].cpu()\n",
    "\n",
    "            best_match_id = None\n",
    "            best_similarity_score = 0.0\n",
    "\n",
    "            # Compare with gallery\n",
    "            if gallery:\n",
    "                gallery_embeddings = np.array([data['embedding'].numpy() for data in gallery.values()])\n",
    "                similarity_scores = cosine_similarity(\n",
    "                    feature.unsqueeze(0).numpy(),\n",
    "                    gallery_embeddings\n",
    "                )[0]\n",
    "                \n",
    "                max_score_idx = np.argmax(similarity_scores)\n",
    "                best_similarity_score = similarity_scores[max_score_idx]\n",
    "                \n",
    "                # Minimum similarity threshold\n",
    "                if best_similarity_score > 0.6:\n",
    "                    best_match_id = list(gallery.keys())[max_score_idx]\n",
    "\n",
    "            if best_match_id is not None:\n",
    "                person_id_map[track_id] = best_match_id\n",
    "            else:\n",
    "                current_person_id = next_person_id\n",
    "                next_person_id += 1\n",
    "\n",
    "                if is_good_enough(resized):\n",
    "                    gallery[current_person_id] = {\n",
    "                        'embedding': feature,\n",
    "                        'face': resized,\n",
    "                        'locked': True  # lock to prevent future updates\n",
    "                    }\n",
    "                    print(f\"Stored GOOD face for new person {current_person_id}\")\n",
    "                else:\n",
    "                    gallery[current_person_id] = {\n",
    "                        'embedding': feature,\n",
    "                        'face': resized,\n",
    "                        'locked': False  # allow future updates\n",
    "                    }\n",
    "                    print(f\"Stored TEMP face for new person {current_person_id}\")\n",
    "\n",
    "                person_id_map[track_id] = current_person_id\n",
    "        \n",
    "        # Draw\n",
    "        pid = person_id_map.get(track_id, \"Unknown\")\n",
    "        label = f\"{pid}\" if isinstance(pid, str) and not pid.isdigit() else f\"Person {pid}\"\n",
    "\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    cv2.putText(frame,str(fps),(20,50),cv2.FONT_HERSHEY_PLAIN,1.5 ,(0,100,250),2)\n",
    "    cv2.imshow(\"ReID + Tracking\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "saved_faces = [data['face'] for data in gallery.values()]\n",
    "n = len(saved_faces)\n",
    "\n",
    "if n == 0:\n",
    "    print(\"No faces saved yet.\")\n",
    "else:\n",
    "    # Grid dimensions\n",
    "    cols = min(n, 5)  # limit to 5 columns\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(3 * cols, 4 * rows))\n",
    "\n",
    "    for i, face in enumerate(saved_faces):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Person {list(gallery.keys())[i]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0c5b8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
