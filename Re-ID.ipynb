{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df130b35-bd87-4316-83ea-29317a594d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwik/Ritwik/Programming/ml/CCTV/deep-person-reid/torchreid/models/osnet.py:482: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(cached_file)\n",
      "/home/ritwik/Ritwik/Programming/miniconda3/envs/projects/lib/python3.12/site-packages/deep_sort_realtime/embedder/embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_wts_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded imagenet pretrained weights from \"/home/ritwik/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n",
      "Model: osnet_x1_0\n",
      "- params: 2,193,616\n",
      "- flops: 978,878,352\n",
      "Track 1 assigned new person ID 0\n",
      "Track 2 assigned new person ID 1\n",
      "Track 3 matched with known person ID 0 (score=0.62)\n",
      "Track 4 assigned new person ID 2\n",
      "Track 5 matched with known person ID 1 (score=0.63)\n",
      "Track 6 matched with known person ID 1 (score=0.65)\n",
      "Track 7 matched with known person ID 1 (score=0.67)\n",
      "Track 9 matched with known person ID 1 (score=0.70)\n",
      "Track 11 matched with known person ID 2 (score=0.80)\n",
      "Track 12 matched with known person ID 2 (score=0.71)\n",
      "Track 13 matched with known person ID 1 (score=0.67)\n",
      "Track 15 matched with known person ID 1 (score=0.65)\n",
      "Track 21 matched with known person ID 0 (score=0.67)\n",
      "Track 22 matched with known person ID 1 (score=0.62)\n",
      "Track 25 matched with known person ID 1 (score=0.71)\n",
      "Track 27 assigned new person ID 3\n",
      "Track 28 matched with known person ID 2 (score=0.63)\n",
      "Track 29 matched with known person ID 3 (score=0.65)\n",
      "Track 31 assigned new person ID 4\n",
      "Track 42 matched with known person ID 2 (score=0.65)\n",
      "Track 48 matched with known person ID 4 (score=0.67)\n",
      "Track 50 matched with known person ID 4 (score=0.68)\n",
      "Track 51 matched with known person ID 4 (score=0.69)\n",
      "Track 52 matched with known person ID 1 (score=0.73)\n",
      "Track 60 assigned new person ID 5\n",
      "Track 62 matched with known person ID 0 (score=0.65)\n",
      "Track 64 matched with known person ID 5 (score=0.60)\n",
      "Track 70 assigned new person ID 6\n",
      "Track 72 matched with known person ID 5 (score=0.72)\n",
      "Track 75 matched with known person ID 4 (score=0.79)\n",
      "Track 77 matched with known person ID 1 (score=0.69)\n",
      "Track 82 matched with known person ID 5 (score=0.71)\n",
      "Track 83 assigned new person ID 7\n",
      "Track 85 matched with known person ID 4 (score=0.62)\n",
      "Track 87 matched with known person ID 6 (score=0.70)\n",
      "Track 88 matched with known person ID 1 (score=0.66)\n",
      "Track 89 matched with known person ID 4 (score=0.75)\n",
      "Track 90 matched with known person ID 5 (score=0.75)\n",
      "Track 92 matched with known person ID 1 (score=0.64)\n",
      "Track 94 matched with known person ID 4 (score=0.60)\n",
      "Track 95 matched with known person ID 4 (score=0.62)\n",
      "Track 102 matched with known person ID 2 (score=0.61)\n",
      "Track 103 matched with known person ID 6 (score=0.72)\n",
      "Track 104 matched with known person ID 4 (score=0.64)\n",
      "Track 105 matched with known person ID 4 (score=0.75)\n",
      "Track 106 matched with known person ID 4 (score=0.67)\n",
      "Track 110 assigned new person ID 8\n",
      "Track 113 matched with known person ID 1 (score=0.63)\n",
      "Track 114 matched with known person ID 4 (score=0.71)\n",
      "Track 116 matched with known person ID 5 (score=0.72)\n",
      "Track 117 matched with known person ID 5 (score=0.66)\n",
      "Track 123 matched with known person ID 2 (score=0.62)\n",
      "Track 127 assigned new person ID 9\n",
      "Track 130 matched with known person ID 9 (score=0.78)\n",
      "Track 134 matched with known person ID 4 (score=0.71)\n",
      "Track 137 matched with known person ID 4 (score=0.65)\n",
      "Track 139 assigned new person ID 10\n",
      "Track 143 matched with known person ID 4 (score=0.67)\n",
      "Track 147 matched with known person ID 5 (score=0.70)\n",
      "Track 149 matched with known person ID 0 (score=0.67)\n",
      "Track 150 matched with known person ID 4 (score=0.67)\n",
      "Track 154 matched with known person ID 8 (score=0.80)\n",
      "Track 156 matched with known person ID 8 (score=0.70)\n",
      "Track 157 matched with known person ID 4 (score=0.74)\n",
      "Track 160 assigned new person ID 11\n",
      "Track 162 matched with known person ID 8 (score=0.84)\n",
      "Track 166 matched with known person ID 6 (score=0.61)\n",
      "Track 168 matched with known person ID 4 (score=0.70)\n",
      "Track 170 assigned new person ID 12\n",
      "Track 173 matched with known person ID 11 (score=0.69)\n",
      "Track 174 matched with known person ID 11 (score=0.74)\n",
      "Track 177 matched with known person ID 4 (score=0.65)\n",
      "Track 178 matched with known person ID 4 (score=0.62)\n",
      "Track 179 assigned new person ID 13\n",
      "Track 186 matched with known person ID 5 (score=0.67)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchreid\n",
    "from scipy.spatial.distance import cosine\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "# Initializing the models\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "extractor = torchreid.utils.FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "# Initializing the DeepSORT tracker\n",
    "tracker = DeepSort(max_age=30, n_init=3)\n",
    "\n",
    "# Gallery to store unique person embeddings\n",
    "gallery = {}\n",
    "next_person_id = 0\n",
    "person_id_map = {}\n",
    "\n",
    "cap = cv2.VideoCapture(\"Raw/shop.mp4\")\n",
    "min_conf = 0.5\n",
    "while True:\n",
    "    detections = []\n",
    "    check, frame = cap.read()\n",
    "    if not check:\n",
    "        break\n",
    "    \n",
    "    # YOLO detection\n",
    "    result = yolo_model(frame, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        if box.cls[0] != 0 or box.conf[0] < min_conf:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "    # DeepSORT tracking\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    \n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        \n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "        \n",
    "        # Check if the track ID is in our person_id map\n",
    "        if track_id not in person_id_map:\n",
    "            # New track ID, perform ReID check\n",
    "            cropped = frame[t:b, l:r]\n",
    "            if cropped.size == 0:\n",
    "                continue\n",
    "            \n",
    "            resized = cv2.resize(cropped, (128, 256))\n",
    "            feature = extractor([resized])[0].cpu()\n",
    "\n",
    "            best_match_id = None\n",
    "            best_similarity_score = 0.0\n",
    "\n",
    "            # Compare with gallery\n",
    "            if gallery:\n",
    "                gallery_embeddings = np.array([data['embedding'].numpy() for data in gallery.values()])\n",
    "                similarity_scores = cosine_similarity(\n",
    "                    feature.unsqueeze(0).numpy(),\n",
    "                    gallery_embeddings\n",
    "                )[0]\n",
    "                \n",
    "                max_score_idx = np.argmax(similarity_scores)\n",
    "                best_similarity_score = similarity_scores[max_score_idx]\n",
    "                \n",
    "                # Minimum similarity threshold\n",
    "                if best_similarity_score > 0.6:\n",
    "                    best_match_id = list(gallery.keys())[max_score_idx]\n",
    "\n",
    "            if best_match_id is not None:\n",
    "                # Match found, link the new track_id to the existing person_id\n",
    "                person_id_map[track_id] = best_match_id\n",
    "                print(f\"Track {track_id} matched with known person ID {best_match_id} (score={best_similarity_score:.2f})\")\n",
    "            else:\n",
    "                # No match found, create a new person ID\n",
    "                current_person_id = next_person_id\n",
    "                next_person_id += 1\n",
    "                \n",
    "                gallery[current_person_id] = {'embedding': feature}\n",
    "                person_id_map[track_id] = current_person_id\n",
    "                print(f\"Track {track_id} assigned new person ID {current_person_id}\")\n",
    "\n",
    "        # Get the person_id from the map\n",
    "        person_id = person_id_map[track_id]\n",
    "        \n",
    "        # Draw\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Person {person_id}\", (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"ReID + Tracking\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9c080-0e4b-4a3b-88df-287f696897dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
