{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cdbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchreid\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- Initialize YOLOv11 model for detection ---\n",
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# --- Initialize Torchreid feature extractor ---\n",
    "extractor = torchreid.utils.FeatureExtractor(\n",
    "    model_name='osnet_x1_0',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# --- Initialize DeepSORT tracker ---\n",
    "tracker = DeepSort(max_age=30, n_init=3)\n",
    "\n",
    "# --- Setup for FPS display ---\n",
    "prev_time = 0\n",
    "\n",
    "# --- In-memory gallery for face embeddings and images ---\n",
    "gallery = {}\n",
    "next_person_id = 0\n",
    "person_id_map = {}\n",
    "\n",
    "# --- Preset named faces (can store multiple photos per person) ---\n",
    "preset_faces = {\n",
    "    \"Nishan\": [\n",
    "        \"data/nishan.png\",\n",
    "        \"data/nishan1.png\",\n",
    "        \"data/nishan2.png\"\n",
    "    ],\n",
    "    \n",
    "    \"Manish\": [\n",
    "        \"data/manish.png\",\n",
    "        \"data/manish1.png\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Load and store preset faces into gallery ---\n",
    "for name, paths in preset_faces.items():\n",
    "    for path in paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"[WARN] Could not load image: {path}\")\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(img, (128, 256))\n",
    "        feature = extractor([resized])[0].cpu()\n",
    "\n",
    "        if name not in gallery:\n",
    "            gallery[name] = []\n",
    "\n",
    "        gallery[name].append({\n",
    "            'embedding': feature,\n",
    "            'face': resized,\n",
    "            'locked': True  # Mark as locked to prevent overwriting\n",
    "        })\n",
    "\n",
    "    print(f\"[INFO] Added {len(gallery[name])} image(s) for {name} to gallery.\")\n",
    "\n",
    "# --- Utility: Image quality checks ---\n",
    "def is_better_image(new_img, old_img):\n",
    "    def sharpness(img):\n",
    "        return cv2.Laplacian(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), cv2.CV_64F).var()\n",
    "    def area(img):\n",
    "        return img.shape[0] * img.shape[1]\n",
    "    return sharpness(new_img) + area(new_img) > sharpness(old_img) + area(old_img)\n",
    "\n",
    "def is_good_enough(image, sharp_thresh=100.0, brightness_thresh=(60, 200)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    mean_brightness = np.mean(gray)\n",
    "    return sharpness > sharp_thresh and brightness_thresh[0] < mean_brightness < brightness_thresh[1]\n",
    "\n",
    "# --- Start webcam feed ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "min_conf = 0.5\n",
    "\n",
    "while True:\n",
    "    detections = []\n",
    "    check, frame = cap.read()\n",
    "    if not check:\n",
    "        break\n",
    "\n",
    "    # --- Calculate FPS ---\n",
    "    cur_time = time.time()\n",
    "    fps = round(1 / (cur_time - prev_time), 2)\n",
    "    prev_time = cur_time\n",
    "\n",
    "    # --- YOLO person detection ---\n",
    "    result = yolo_model(frame, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        if int(box.cls[0]) != 0 or float(box.conf[0]) < min_conf:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = float(box.conf[0])\n",
    "        detections.append(([x1, y1, x2 - x1, y2 - y1], conf, 'person'))\n",
    "\n",
    "    # --- Track people using DeepSORT ---\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "    \n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "        cropped = frame[t:b, l:r]\n",
    "        if cropped.size == 0:\n",
    "            continue\n",
    "\n",
    "        resized = cv2.resize(cropped, (128, 256))\n",
    "        feature = extractor([resized])[0].cpu()\n",
    "\n",
    "        # --- Assign ID or Name ---\n",
    "        if track_id not in person_id_map:\n",
    "            best_match_id = None\n",
    "            best_similarity_score = 0.0\n",
    "\n",
    "            # Compare with all known gallery faces\n",
    "            for person_name, faces in gallery.items():\n",
    "                for face_data in faces:\n",
    "                    score = cosine_similarity(\n",
    "                        feature.unsqueeze(0).numpy(),\n",
    "                        face_data['embedding'].unsqueeze(0).numpy()\n",
    "                    )[0][0]\n",
    "                    if score > best_similarity_score:\n",
    "                        best_similarity_score = score\n",
    "                        best_match_id = person_name\n",
    "\n",
    "            # If match is strong enough\n",
    "            if best_similarity_score > 0.6:\n",
    "                person_id_map[track_id] = best_match_id\n",
    "            else:\n",
    "                # Assign numeric ID\n",
    "                current_id = str(next_person_id)\n",
    "                next_person_id += 1\n",
    "                gallery[current_id] = [{\n",
    "                    'embedding': feature,\n",
    "                    'face': resized,\n",
    "                    'locked': is_good_enough(resized)\n",
    "                }]\n",
    "                print(f\"[INFO] Stored {'GOOD' if gallery[current_id][0]['locked'] else 'TEMP'} face for new person {current_id}\")\n",
    "                person_id_map[track_id] = current_id\n",
    "\n",
    "        else:\n",
    "            # If already known track, check for better image\n",
    "            pid = person_id_map[track_id]\n",
    "            faces = gallery[pid]\n",
    "            if all(not f['locked'] for f in faces):\n",
    "                current_best = faces[0]\n",
    "                if is_good_enough(resized) and is_better_image(resized, current_best['face']):\n",
    "                    gallery[pid][0] = {\n",
    "                        'embedding': feature,\n",
    "                        'face': resized,\n",
    "                        'locked': True\n",
    "                    }\n",
    "                    print(f\"[INFO] Updated {pid} with better GOOD image\")\n",
    "\n",
    "        # --- Draw bounding box and label ---\n",
    "        pid = person_id_map[track_id]\n",
    "        label = pid if not pid.isdigit() else f\"Person {pid}\"\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # --- Show FPS ---\n",
    "    cv2.putText(frame, f\"FPS: {fps}\", (20, 50), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 100, 255), 2)\n",
    "\n",
    "    # --- Display the frame ---\n",
    "    cv2.imshow(\"ReID + Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Collect all stored face images from gallery\n",
    "saved_faces = []\n",
    "face_labels = []\n",
    "\n",
    "for person_id, face_entries in gallery.items():\n",
    "    for idx, entry in enumerate(face_entries):\n",
    "        saved_faces.append(entry['face'])\n",
    "        label = person_id if len(face_entries) == 1 else f\"{person_id} #{idx+1}\"\n",
    "        face_labels.append(label)\n",
    "\n",
    "n = len(saved_faces)\n",
    "\n",
    "if n == 0:\n",
    "    print(\"No faces saved yet.\")\n",
    "else:\n",
    "    # Grid layout: 5 images per row\n",
    "    cols = min(n, 5)\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=(3 * cols, 4 * rows))\n",
    "\n",
    "    for i, face in enumerate(saved_faces):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(face_labels[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0c5b8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
